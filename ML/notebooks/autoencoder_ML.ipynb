{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LNcxA0ln-G7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os, warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"smart_home_dataset.csv\", nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KGLZtTrE-gFM"
   },
   "outputs": [],
   "source": [
    "#the autoencoder model\n",
    "class AE(nn.Module):\n",
    "  #initialise the model, ran before saving the model\n",
    "    def __init__(self, n_past, n_future, n_features):\n",
    "        super(AE, self).__init__()\n",
    "        # the autoencoder LSTM itself\n",
    "        self.encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "        self.encoder_l1 = tf.keras.layers.LSTM(100,return_sequences = True, return_state=True)\n",
    "        self.encoder_outputs1 = self.encoder_l1(self.encoder_inputs)\n",
    "        self.encoder_states1 = self.encoder_outputs1[1:]\n",
    "\n",
    "        self.encoder_l2 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "        self.encoder_outputs2 = self.encoder_l2(self.encoder_outputs1[0])\n",
    "        self.encoder_states2 = self.encoder_outputs2[1:]\n",
    "\n",
    "        self.decoder_inputs = tf.keras.layers.RepeatVector(n_future)(self.encoder_outputs2[0])\n",
    "\n",
    "        self.decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(self.decoder_inputs,initial_state = self.encoder_states1)\n",
    "        self.decoder_l2 = tf.keras.layers.LSTM(100, return_sequences=True)(self.decoder_l1,initial_state = self.encoder_states2)\n",
    "        self.decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(self.decoder_l2)\n",
    "        self.model = tf.keras.models.Model(self.encoder_inputs,self.decoder_outputs2)\n",
    "\n",
    "  #train the model, run ONCE, takes in X_train, Y_train, X_val, Y_val, Adam optimizer\n",
    "  # for dimensions, see data preprocessing\n",
    "    def train_model(self, X_train, Y_train, X_val, Y_val, optimizer):\n",
    "        reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
    "        self.model.compile(optimizer=optimizer, loss=tf.keras.losses.Huber(), metrics=['accuracy'])\n",
    "        self.model.fit(X_train,Y_train,epochs=25,validation_data=(X_val,Y_val),batch_size=128,verbose=2,callbacks=[reduce_lr])\n",
    "\n",
    "    # tests the model, returns test accuracy\n",
    "    def test_model(self, X_test, Y_test):\n",
    "        scores = self.model.evaluate(X_test, Y_test)\n",
    "        test_accuracy = scores[1]*100\n",
    "        return test_accuracy\n",
    "\n",
    "    def test_anomaly(self, X_test, Y_test, threshold):\n",
    "        scores = self.model.evaluate(X_test, Y_test)\n",
    "        test_accuracy = scores*100\n",
    "\n",
    "        print(f'Test Accuracy: {test_accuracy}')\n",
    "        return 1 if test_accuracy > threshold else 0\n",
    "    \n",
    "n_past = 60*24\n",
    "n_future = 10\n",
    "columns = ['temperature','relative_humidity','light_switch', 'ultrasonic','pir', 'pressure']\n",
    "n_features = len(columns)\n",
    "\n",
    "ae = AE(n_past, n_future, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "JIL0JzuAPhUa"
   },
   "outputs": [],
   "source": [
    "d = np.array(data[columns])\n",
    "df = pd.DataFrame(d, columns = columns)\n",
    "\n",
    "#scale the feature values to between -1 and 1\n",
    "data = df\n",
    "scalers={}\n",
    "for i in df.columns:\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    s_s = scaler.fit_transform(data[i].values.reshape(-1,1))\n",
    "    s_s=np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+ str(i)] = scaler\n",
    "    data[i]=s_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "GjdqKbcoPjGJ"
   },
   "outputs": [],
   "source": [
    "# Define proportions\n",
    "TEST_PROP = 0.3\n",
    "VAL_PROP = 0.2\n",
    "\n",
    "# Calculate data lengths\n",
    "total_length = len(data)\n",
    "train_val_length = int(total_length * (1 - TEST_PROP))\n",
    "train_length = int(train_val_length * (1 - VAL_PROP))\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train = data[:train_length]\n",
    "val = data[train_length:train_val_length]\n",
    "test = data[train_val_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "5UK0auFAPk3z"
   },
   "outputs": [],
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "    X, y = [], []\n",
    "    \n",
    "    # for each series, a window of (n_past + n_future + 1) is created\n",
    "    for i in range(len(series) - n_past - n_future + 1):\n",
    "        X.append(series[i:i + n_past])\n",
    "        y.append(series[i + n_past:i + n_past + n_future])\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, Y_train = split_series(train, n_past, n_future)\n",
    "X_val, Y_val = split_series(val, n_past, n_future)\n",
    "X_test, Y_test = split_series(test.values, n_past, n_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSf7bx3UPw5P",
    "outputId": "c98fdbcd-055f-4e73-d9af-31e424f0350d"
   },
   "outputs": [],
   "source": [
    "# ae.train_model(X_train, Y_train, X_val, Y_val, optimizer)\n",
    "\n",
    "# PATH = \"autoencoder_trained.pt\"\n",
    "# torch.save(ae, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8GELvQbs25O",
    "outputId": "12a0b386-3ac5-40f3-9814-bd79fe72fac1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AE()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"autoencoder.pt\"\n",
    "\n",
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 16s 324ms/step - loss: 0.0115 - accuracy: 0.9720\n",
      "Test accuracy:  97.19535708427429 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.test_model(X_test, Y_test)\n",
    "print('Test accuracy: ', test_accuracy, '%')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
